{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5aeedf9c-1974-4a32-908b-3f2c90596b1f",
   "metadata": {},
   "source": [
    "## This notebook focus on generating a MELT matrix table from MELT VCFs for validation datasets\n",
    "- The MELT VCF contain samples for 15x and 30x \n",
    "- So split the dataset then process them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d211bbec-c078-43f4-bbf8-e4997e408f54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Current session configs: <tt>{'driverMemory': '6000M', 'proxyUser': 'jovyan', 'kind': 'pyspark'}</tt><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%configure -f\n",
    "{\"driverMemory\": \"6000M\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46ba5a12-0683-4d44-aa02-9c36ead9a519",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pip-installed Hail requires additional configuration options in Spark referring\n",
      "  to the path to the Hail Python module directory HAIL_DIR,\n",
      "  e.g. /path/to/python/site-packages/hail:\n",
      "    spark.jars=HAIL_DIR/hail-all-spark.jar\n",
      "    spark.driver.extraClassPath=HAIL_DIR/hail-all-spark.jar\n",
      "    spark.executor.extraClassPath=./hail-all-spark.jarRunning on Apache Spark version 3.1.2-amzn-0\n",
      "SparkUI available at\n",
      "Welcome to\n",
      "     __  __     <>__\n",
      "    / /_/ /__  __/ /\n",
      "   / __  / _ `/ / /\n",
      "  /_/ /_/\\_,_/_/_/   version 0.2.80-4ccfae1ff293\n",
      "LOGGING: writing to "
     ]
    }
   ],
   "source": [
    "import hail as hl\n",
    "hl.init(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b2d53ff-d556-4364-9f7a-b2eecbd07e3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## list all resources  used in this notebook \n",
    "\n",
    "release_10_melt_sva_vcf_uri = \"SVA.final_comp.sorted.vcf.gz\"\n",
    "release_10_melt_line_vcf_uri = \"LINE1.final_comp.sorted.vcf.gz\"\n",
    "release_10_melt_alu_vcf_uri = \"ALU.final_comp.sorted.vcf.gz\"\n",
    "\n",
    "whiltelist_region_bed_uri = \"resources_broad_hg38_v0_wgs_calling_regions.hg38.merged.autosome_only-minus_excl_regions.bed\"\n",
    "\n",
    "validation15x_sample_txt_uri = \"SG10K-SV-Release-1.3_15xValidation.samples.txt\"\n",
    "validation30x_sample_txt_uri = \"SG10K-SV-Release-1.3_30xValidation.samples.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a810b87e-9a9a-4c3b-8321-49b4512fa242",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load MELT VCFs\n",
    "sva_mt = hl.import_vcf(release_10_melt_sva_vcf_uri,   reference_genome=\"GRCh38\", force_bgz=True)\n",
    "line_mt = hl.import_vcf(release_10_melt_line_vcf_uri, reference_genome=\"GRCh38\", force_bgz=True)\n",
    "alu_mt = hl.import_vcf(release_10_melt_alu_vcf_uri,   reference_genome=\"GRCh38\", force_bgz=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf5c4d4-6638-48cd-bec5-84d77a6759ed",
   "metadata": {},
   "source": [
    "## 15x Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c9f7673-4ec0-4828-b145-7f9be1b75834",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Global fields:\n",
      "    None\n",
      "----------------------------------------\n",
      "Column fields:\n",
      "    's': str\n",
      "----------------------------------------\n",
      "Row fields:\n",
      "    'locus': locus<GRCh38>\n",
      "    'alleles': array<str>\n",
      "    'rsid': str\n",
      "    'qual': float64\n",
      "    'filters': set<str>\n",
      "    'info': struct {\n",
      "        ASSESS: int32, \n",
      "        TSD: str, \n",
      "        INTERNAL: array<str>, \n",
      "        SVTYPE: str, \n",
      "        SVLEN: int32, \n",
      "        MEINFO: array<str>, \n",
      "        DIFF: array<str>, \n",
      "        LP: int32, \n",
      "        RP: int32, \n",
      "        RA: float64, \n",
      "        PRIOR: str, \n",
      "        SR: int32\n",
      "    }\n",
      "----------------------------------------\n",
      "Entry fields:\n",
      "    'GT': call\n",
      "    'GL': array<float64>\n",
      "    'DP': int32\n",
      "    'AD': int32\n",
      "    'PL': array<int32>\n",
      "----------------------------------------\n",
      "Column key: ['s']\n",
      "Row key: ['locus', 'alleles']\n",
      "----------------------------------------\n",
      "(168965, 1523)\n",
      "2024-05-06 07:42:21 Hail: INFO: Reading table without type imputation\n",
      "  Loading field 's' as type str (not specified)\n",
      "2024-05-06 07:42:39 Hail: INFO: Ordering unsorted dataset with shuffle\n",
      "2024-05-06 07:42:46 Hail: INFO: Ordering unsorted dataset with network shuffle\n",
      "2024-05-06 07:43:06 Hail: INFO: Ordering unsorted dataset with shuffle\n",
      "2024-05-06 07:43:17 Hail: INFO: Ordering unsorted dataset with network shuffle\n",
      "2024-05-06 07:43:19 Hail: INFO: Ordering unsorted dataset with shuffle\n",
      "2024-05-06 07:43:21 Hail: INFO: Ordering unsorted dataset with network shuffle\n",
      "2024-05-06 07:43:29 Hail: INFO: Ordering unsorted dataset with shuffle\n",
      "2024-05-06 07:43:34 Hail: INFO: Ordering unsorted dataset with network shuffle\n",
      "2024-05-06 07:43:45 Hail: INFO: Ordering unsorted dataset with shuffle\n",
      "2024-05-06 07:43:56 Hail: INFO: Ordering unsorted dataset with network shuffle\n",
      "2024-05-06 07:43:58 Hail: INFO: Ordering unsorted dataset with shuffle\n",
      "2024-05-06 07:43:59 Hail: INFO: Ordering unsorted dataset with network shuffle"
     ]
    }
   ],
   "source": [
    "## filer for relevant samples 15x\n",
    "def clean_melt_sample(sample_ht, mt):\n",
    "    mt = mt.key_cols_by()\n",
    "    mt2 = mt.annotate_cols(s = mt.s.replace( \".bqsr\", \"\"))\n",
    "    mt2 = mt2.key_cols_by('s')\n",
    "    mt2 = mt2.filter_cols(hl.is_defined(sample_ht[mt2.col_key]))\n",
    "    return mt2 \n",
    "\n",
    "## remove INFO/ISTP\n",
    "line_mt = line_mt.annotate_rows(info = line_mt.info.drop('ISTP'))\n",
    "\n",
    "sample_ht = hl.import_table(validation15x_sample_txt_uri).key_by('s')\n",
    "#[clean_melt_sample(sample_ht, mt) for mt in melt_mts] ## list completion does not work in this context \n",
    "line_15x_mt = clean_melt_sample(sample_ht, line_mt)\n",
    "alu_15x_mt = clean_melt_sample(sample_ht, alu_mt)\n",
    "sva_15x_mt = clean_melt_sample(sample_ht, sva_mt)\n",
    "\n",
    "\n",
    "## merge \n",
    "melt_15x_mts = [line_15x_mt, alu_15x_mt, sva_15x_mt]\n",
    "mt15 = hl.MatrixTable.union_rows(*melt_15x_mts)\n",
    "mt15.describe()\n",
    "mt15.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8de30775-b29f-4997-a056-19faa9c10e83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(168965, 1523)\n",
      "2024-05-06 07:45:04 Hail: INFO: Ordering unsorted dataset with shuffle\n",
      "2024-05-06 07:45:09 Hail: INFO: Ordering unsorted dataset with network shuffle\n",
      "2024-05-06 07:45:19 Hail: INFO: Ordering unsorted dataset with shuffle\n",
      "2024-05-06 07:45:28 Hail: INFO: Ordering unsorted dataset with network shuffle\n",
      "2024-05-06 07:45:30 Hail: INFO: Ordering unsorted dataset with shuffle\n",
      "2024-05-06 07:45:31 Hail: INFO: Ordering unsorted dataset with network shuffle"
     ]
    }
   ],
   "source": [
    "mt15.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b77ac454-3054-4b94-9ebf-68f1e296fbed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(168965, 1523)\n",
      "(12556, 1523)\n",
      "2024-05-06 07:47:32 Hail: INFO: Ordering unsorted dataset with shuffle\n",
      "2024-05-06 07:47:38 Hail: INFO: Ordering unsorted dataset with network shuffle\n",
      "2024-05-06 07:47:57 Hail: INFO: Ordering unsorted dataset with shuffle\n",
      "2024-05-06 07:48:08 Hail: INFO: Ordering unsorted dataset with network shuffle\n",
      "2024-05-06 07:48:09 Hail: INFO: Ordering unsorted dataset with shuffle\n",
      "2024-05-06 07:48:11 Hail: INFO: Ordering unsorted dataset with network shuffle\n",
      "2024-05-06 07:48:25 Hail: INFO: Reading table without type imputation\n",
      "  Loading field 'f0' as type str (user-supplied)\n",
      "  Loading field 'f1' as type int32 (user-supplied)\n",
      "  Loading field 'f2' as type int32 (user-supplied)\n",
      "2024-05-06 07:48:34 Hail: INFO: Ordering unsorted dataset with network shuffle\n",
      "2024-05-06 07:48:43 Hail: INFO: Ordering unsorted dataset with network shuffle\n",
      "2024-05-06 07:48:45 Hail: INFO: Ordering unsorted dataset with network shuffle\n",
      "2024-05-06 07:48:45 Hail: INFO: Coerced sorted dataset"
     ]
    }
   ],
   "source": [
    "##\n",
    "## filter relevant variant\n",
    "##\n",
    "## 2- contains \"PASS\", \"{fail}\" FILTER entries We only carry fwd \"FILTER=PASS\" entries \n",
    "## 5- contains monomorphic entries. We only carry fwd entries wit at least one hom-ref and drop monomorphic entries\n",
    "## 7- contains SV outside of our predefind whitlist region (ie not low-cpmplexity, telemore, centromere, ...) \n",
    "print(mt15.count()) ## \n",
    "\n",
    "\n",
    "## load the predefine whitlist region (ie not low-cpmplexity, telemore, centromere, ...) \n",
    "whitelist_region= hl.import_bed(whiltelist_region_bed_uri, reference_genome='GRCh38')\n",
    "\n",
    "## filter relevant variant\n",
    "mt15 = mt15.filter_rows(\n",
    "    True\n",
    "    & (mt15.filters.length() == 0)                                ## We only carry fwd \"FILTER=PASS\" entries \n",
    "    & (hl.agg.any(mt15.GT.is_hom_ref()))                          ## We only carry fwd entries with at least one hom-ref\n",
    "    & (hl.if_else(hl.agg.any(hl.is_missing(mt15.GT)),             ## We only carry fwd polumorphic entries \n",
    "                  hl.agg.counter(mt15.GT).size() > 2,             ##       that is GT contain NA + at least 2 of 0/0, 0/1, 1/1  \n",
    "                  hl.agg.counter(mt15.GT).size() > 1 ))           ##       that is GT contain at least 2 of 0/0, 0/1, 1/1  \n",
    "    & (hl.is_defined(whitelist_region[mt15.locus]))               ## We only carry fwd  whitelist region contained SV \n",
    "    , keep=True)\n",
    "\n",
    "print(mt15.count()) ## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a9a06dd-2978-48bf-ad27-ff89aba7bc26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-06 07:51:53 Hail: INFO: Ordering unsorted dataset with network shuffle\n",
      "2024-05-06 07:52:13 Hail: INFO: Ordering unsorted dataset with network shuffle\n",
      "2024-05-06 07:52:14 Hail: INFO: Ordering unsorted dataset with network shuffle\n",
      "2024-05-06 07:52:15 Hail: INFO: Coerced sorted dataset\n",
      "2024-05-06 07:53:51 Hail: INFO: wrote matrix table with 12556 rows and 1523 columns in 13 partitions to SG10K_SV_MELT_validation15x.n1523.m12556.15xvalidation.mt\n",
      "    Total size: 77.04 MiB\n",
      "    * Rows/entries: 77.04 MiB\n",
      "    * Columns: 5.97 KiB\n",
      "    * Globals: 11.00 B\n",
      "    * Smallest partition: 0 rows (20.00 B)\n",
      "    * Largest partition:  1519 rows (9.10 MiB)"
     ]
    }
   ],
   "source": [
    "## write the resulting mt\n",
    "release14_15xv_melt_mt_uri =   \"SG10K_SV_MELT_validation15x.n1523.m12556.15xvalidation.mt\"\n",
    "\n",
    "mt15.write(release14_15xv_melt_mt_uri, overwrite=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9140ac4-8046-4a71-89dd-67c82f869b8c",
   "metadata": {},
   "source": [
    "## 30x validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "35e22704-3877-45e3-9270-39de1015962e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Global fields:\n",
      "    None\n",
      "----------------------------------------\n",
      "Column fields:\n",
      "    's': str\n",
      "----------------------------------------\n",
      "Row fields:\n",
      "    'locus': locus<GRCh38>\n",
      "    'alleles': array<str>\n",
      "    'rsid': str\n",
      "    'qual': float64\n",
      "    'filters': set<str>\n",
      "    'info': struct {\n",
      "        ASSESS: int32, \n",
      "        TSD: str, \n",
      "        INTERNAL: array<str>, \n",
      "        SVTYPE: str, \n",
      "        SVLEN: int32, \n",
      "        MEINFO: array<str>, \n",
      "        DIFF: array<str>, \n",
      "        LP: int32, \n",
      "        RP: int32, \n",
      "        RA: float64, \n",
      "        PRIOR: str, \n",
      "        SR: int32\n",
      "    }\n",
      "----------------------------------------\n",
      "Entry fields:\n",
      "    'GT': call\n",
      "    'GL': array<float64>\n",
      "    'DP': int32\n",
      "    'AD': int32\n",
      "    'PL': array<int32>\n",
      "----------------------------------------\n",
      "Column key: ['s']\n",
      "Row key: ['locus', 'alleles']\n",
      "----------------------------------------\n",
      "(168965, 1922)\n",
      "2024-05-06 07:57:01 Hail: INFO: Reading table without type imputation\n",
      "  Loading field 's' as type str (not specified)\n",
      "2024-05-06 07:57:15 Hail: INFO: Ordering unsorted dataset with shuffle\n",
      "2024-05-06 07:57:21 Hail: INFO: Ordering unsorted dataset with network shuffle\n",
      "2024-05-06 07:57:40 Hail: INFO: Ordering unsorted dataset with shuffle\n",
      "2024-05-06 07:57:50 Hail: INFO: Ordering unsorted dataset with network shuffle\n",
      "2024-05-06 07:57:52 Hail: INFO: Ordering unsorted dataset with shuffle\n",
      "2024-05-06 07:57:54 Hail: INFO: Ordering unsorted dataset with network shuffle\n",
      "2024-05-06 07:58:01 Hail: INFO: Ordering unsorted dataset with shuffle\n",
      "2024-05-06 07:58:06 Hail: INFO: Ordering unsorted dataset with network shuffle\n",
      "2024-05-06 07:58:16 Hail: INFO: Ordering unsorted dataset with shuffle\n",
      "2024-05-06 07:58:26 Hail: INFO: Ordering unsorted dataset with network shuffle\n",
      "2024-05-06 07:58:28 Hail: INFO: Ordering unsorted dataset with shuffle\n",
      "2024-05-06 07:58:30 Hail: INFO: Ordering unsorted dataset with network shuffle"
     ]
    }
   ],
   "source": [
    "## filer for relevant samples 30x\n",
    "def clean_melt_sample(sample_ht, mt):\n",
    "    mt = mt.key_cols_by()\n",
    "    mt2 = mt.annotate_cols(s = mt.s.replace( \".bqsr\", \"\"))\n",
    "    mt2 = mt2.key_cols_by('s')\n",
    "    mt2 = mt2.filter_cols(hl.is_defined(sample_ht[mt2.col_key]))\n",
    "    return mt2 \n",
    "\n",
    "\n",
    "sample_30_ht = hl.import_table(validation30x_sample_txt_uri).key_by('s')\n",
    "#[clean_melt_sample(sample_ht, mt) for mt in melt_mts] ## list completion does not work in this context \n",
    "line_30x_mt = clean_melt_sample(sample_30_ht, line_mt)\n",
    "alu_30x_mt = clean_melt_sample(sample_30_ht, alu_mt)\n",
    "sva_30x_mt = clean_melt_sample(sample_30_ht, sva_mt)\n",
    "\n",
    "\n",
    "## merge \n",
    "melt_30x_mts = [line_30x_mt, alu_30x_mt, sva_30x_mt]\n",
    "mt30 = hl.MatrixTable.union_rows(*melt_30x_mts)\n",
    "mt30.describe()\n",
    "mt30.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "60ce52e5-0ecd-4e0f-8f5e-a6d319943084",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(168965, 1922)\n",
      "(14025, 1922)\n",
      "2024-05-06 08:00:05 Hail: INFO: Ordering unsorted dataset with shuffle\n",
      "2024-05-06 08:00:12 Hail: INFO: Ordering unsorted dataset with network shuffle\n",
      "2024-05-06 08:00:31 Hail: INFO: Ordering unsorted dataset with shuffle\n",
      "2024-05-06 08:00:41 Hail: INFO: Ordering unsorted dataset with network shuffle\n",
      "2024-05-06 08:00:43 Hail: INFO: Ordering unsorted dataset with shuffle\n",
      "2024-05-06 08:00:45 Hail: INFO: Ordering unsorted dataset with network shuffle\n",
      "2024-05-06 08:00:58 Hail: INFO: Reading table without type imputation\n",
      "  Loading field 'f0' as type str (user-supplied)\n",
      "  Loading field 'f1' as type int32 (user-supplied)\n",
      "  Loading field 'f2' as type int32 (user-supplied)\n",
      "2024-05-06 08:01:04 Hail: INFO: Ordering unsorted dataset with network shuffle\n",
      "2024-05-06 08:01:13 Hail: INFO: Ordering unsorted dataset with network shuffle\n",
      "2024-05-06 08:01:15 Hail: INFO: Ordering unsorted dataset with network shuffle\n",
      "2024-05-06 08:01:15 Hail: INFO: Coerced sorted dataset"
     ]
    }
   ],
   "source": [
    "##\n",
    "## filter relevant variant\n",
    "##\n",
    "## 2- contains \"PASS\", \"{fail}\" FILTER entries We only carry fwd \"FILTER=PASS\" entries \n",
    "## 5- contains monomorphic entries. We only carry fwd entries wit at least one hom-ref and drop monomorphic entries\n",
    "## 7- contains SV outside of our predefind whitlist region (ie not low-cpmplexity, telemore, centromere, ...)\n",
    "\n",
    "print(mt30.count()) ## \n",
    "\n",
    "\n",
    "## load the predefine whitlist region (ie not low-cpmplexity, telemore, centromere, ...) \n",
    "whitelist_region= hl.import_bed(whiltelist_region_bed_uri, reference_genome='GRCh38')\n",
    "\n",
    "## filter relevant variant\n",
    "mt30 = mt30.filter_rows(\n",
    "    True\n",
    "    & (mt30.filters.length() == 0)                                ## We only carry fwd \"FILTER=PASS\" entries \n",
    "    & (hl.agg.any(mt30.GT.is_hom_ref()))                          ## We only carry fwd entries with at least one hom-ref\n",
    "    & (hl.if_else(hl.agg.any(hl.is_missing(mt30.GT)),             ## We only carry fwd polumorphic entries \n",
    "                  hl.agg.counter(mt30.GT).size() > 2,             ##       that is GT contain NA + at least 2 of 0/0, 0/1, 1/1  \n",
    "                  hl.agg.counter(mt30.GT).size() > 1 ))           ##       that is GT contain at least 2 of 0/0, 0/1, 1/1  \n",
    "    & (hl.is_defined(whitelist_region[mt30.locus]))               ## We only carry fwd  whitelist region contained SV \n",
    "    , keep=True)\n",
    "\n",
    "print(mt30.count()) ## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cf4afd69-ef64-4b4b-a753-960b406ffaba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-06 08:24:40 Hail: INFO: Ordering unsorted dataset with network shuffle\n",
      "2024-05-06 08:24:59 Hail: INFO: Ordering unsorted dataset with network shuffle\n",
      "2024-05-06 08:25:00 Hail: INFO: Ordering unsorted dataset with network shuffle\n",
      "2024-05-06 08:25:01 Hail: INFO: Coerced sorted dataset\n",
      "2024-05-06 08:26:42 Hail: INFO: wrote matrix table with 14025 rows and 1922 columns in 13 partitions to SG10K_SV_MELT_validation30x.n1922.m14025.30xvalidation.mt\n",
      "    Total size: 109.98 MiB\n",
      "    * Rows/entries: 109.97 MiB\n",
      "    * Columns: 7.52 KiB\n",
      "    * Globals: 11.00 B\n",
      "    * Smallest partition: 0 rows (20.00 B)\n",
      "    * Largest partition:  1743 rows (13.35 MiB)"
     ]
    }
   ],
   "source": [
    "## write the resulting mt\n",
    "release14_30xv_melt_mt_uri =   \"SG10K_SV_MELT_validation30x.n1922.m14025.30xvalidation.mt\"\n",
    "\n",
    "mt30.write(release14_30xv_melt_mt_uri, overwrite=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78cbb636-7105-4721-a2b1-11832515394c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
